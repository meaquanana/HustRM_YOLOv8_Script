# Ultralytics YOLO ðŸš€, AGPL-3.0 license
# YOLOv5 object detection model with P3-P5 outputs. For details see https://docs.ultralytics.com/models/yolov5

# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov5n.yaml' will call yolov5.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]
  s: [0.33, 0.50, 1024]
  m: [0.67, 0.75, 1024]
  l: [1.00, 1.00, 1024]
  x: [1.33, 1.25, 1024]

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]

# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]], # 10
   [4, 1, Conv, [512, 1, 1]], # 11
   [[-1, 6, -2], 1, Zoom_cat, []],  # 12 cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]], # 14
   [2, 1, Conv, [256, 1, 1]], # 15
   [[-1, 4, -2], 1, Zoom_cat, []],  # 16  cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]], # 18
   [[-1, 14], 1, Concat, [1]],  # 19 cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]], # 21
   [[-1, 10], 1, Concat, [1]],  # 22 cat head P5
   [-1, 3, C3, [512, False]],  # 23 (P5/32-large)

   [[4, 6, 8], 1, ScalSeq, [256]], # 24 args[inchane]
   [[17, -1], 1, Add, []], # 25
  #  [[17, -1], 1, asf_attention_model, []] # 25

   [-1, 1, nn.Upsample, [None, 2, 'nearest']], # 26
   [[-1, 2], 1, Concat, []], # 27 cat backbone P2
   [-1, 3, C3, [128]], # 28 (P2/4-small)

   [[2, 25, 20], 1, ScalSeq, [128]], # 29 args[channel]
   [[28, -1], 1, Add, []], # 30
  #  [[28, -1], 1, asf_attention_model, []] # 30

   [[30, 25, 20, 23], 1, Detect, [nc]],  # RTDETRDecoder(P3, P4, P5)
  ]